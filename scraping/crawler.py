# scraping/crawler.py

"""
R√¥le global :
Ce module est responsable de la collecte de donn√©es √† partir de sites web, qu'ils soient statiques ou dynamiques, 
et de leur analyse s√©mantique. Il agit comme un orchestrateur, combinant les √©tapes de scraping et d'analyse pour produire 
un r√©sultat structur√© et exploitable.

Pourquoi il est important :
Dans le pipeline global (scraping ‚Üí analyse ‚Üí visualisation ‚Üí rapport), ce module est une pi√®ce ma√Ætresse. 
Il automatise la d√©tection du type de site (statique ou dynamique), extrait les donn√©es pertinentes et les analyse 
pour les structurer. Sans cette √©tape, il serait impossible de transformer les donn√©es brutes des sites web en informations 
organis√©es et pr√™tes √† √™tre utilis√©es dans des rapports ou des visualisations.

Comment il aide dans le pipeline :
- **Scraping** : Identifie le type de site et utilise la m√©thode appropri√©e pour extraire les donn√©es.
- **Analyse** : Passe les donn√©es extraites √† l'analyseur s√©mantique pour les enrichir et les structurer.
- **Visualisation** : Pr√©pare les donn√©es pour qu'elles puissent √™tre utilis√©es dans des graphiques ou des tableaux.
- **Rapport** : Fournit des informations claires et organis√©es pour les int√©grer dans des rapports professionnels.

Technologies utilis√©es :
- **D√©tection statique/dynamique** : Utilise une fonction pour d√©terminer si le site est statique ou dynamique.
- **Scraping statique et dynamique** : Int√®gre des modules sp√©cialis√©s pour extraire les donn√©es en fonction du type de site.
- **Analyse s√©mantique** : Utilise un analyseur s√©mantique pour structurer et enrichir les donn√©es extraites.
- **Logging** : Permet de suivre les √©tapes du processus et de g√©rer les erreurs de mani√®re transparente.
"""

import logging
from utils.detection import is_static_site
from scraping.scraper_static import scrape_static_site
from scraping.scraper_dynamic import scrape_dynamic_site
from analyse.analyseur_semantique import analyse_semantique

def crawl_site(url):
    """
    R√¥le :
    Cette fonction est le point d'entr√©e principal pour scraper un site web et effectuer une analyse s√©mantique. 
    Elle d√©tecte si le site est statique ou dynamique, utilise la m√©thode appropri√©e pour extraire les donn√©es, 
    puis les passe √† l'analyseur s√©mantique pour les structurer.

    Fonctionnalit√© :
    - D√©tecte automatiquement si le site est statique ou dynamique.
    - Utilise un scraper adapt√© pour extraire les donn√©es du site.
    - Effectue une analyse s√©mantique sur les blocs de donn√©es extraits.
    - Retourne un dictionnaire structur√© contenant les informations analys√©es.

    Importance :
    Cette fonction automatise l'ensemble du processus de collecte et d'analyse des donn√©es d'un site web. 
    Elle garantit que les donn√©es extraites sont pr√™tes √† √™tre utilis√©es dans les √©tapes suivantes du pipeline.

    Arguments :
    - `url` : L'URL du site web √† scraper.

    Retour :
    Un dictionnaire structur√© contenant les informations extraites et analys√©es.
    """
    try:
        # D√©tection du type de site (statique ou dynamique)
        is_static = is_static_site(url)
        logging.info(f"üîç D√©tection du type de site : {'statique' if is_static else 'dynamique'}")

        # Scraping en fonction du type de site
        data = scrape_static_site(url) if is_static else scrape_dynamic_site(url)
        if not data:
            logging.warning(f"‚ö†Ô∏è Aucune donn√©e extraite de {url}")
            return {"name": url, "url": url, "summary": "R√©sum√© non disponible."}

        # Analyse s√©mantique sur les blocs HTML extraits
        raw_blocks = data.get("raw_blocks", [])
        analyse = analyse_semantique(raw_blocks, url)

        # Retourne les donn√©es structur√©es
        return {"name": data.get("name", url), "url": url, **analyse}

    except Exception as e:
        # Gestion des erreurs et retour d'un r√©sultat minimal
        logging.error(f"‚ùå Erreur dans crawl_site pour {url}: {str(e)}")
        return {"name": url, "url": url, "summary": "R√©sum√© non disponible."}
