# ğŸ“Š Projet Veille concurrentielle automatisÃ©e avec IA  â€” Dashboard & Analyse de donnÃ©es

Ce projet permet de **scraper, nettoyer, analyser et visualiser** des donnÃ©es d'entreprises et freelances, avec gÃ©nÃ©ration automatique de rapports PDF et graphiques.  
Il intÃ¨gre du **NLP** (analyse sÃ©mantique, TF-IDF), de la **visualisation** et une **interface Dashboard**. C'est une solution intelligente qui **collecte, analyse et prÃ©sente automatiquement** des donnÃ©es issues du web  
(sites de concurrents, plateformes de freelancing, annuaires professionnelsâ€¦)  
afin d'aider les Ã©quipes commerciales Ã  :
- Mieux comprendre le marchÃ©
- Surveiller la concurrence
- DÃ©tecter de nouvelles opportunitÃ©s

---
## ğŸ“‚ Structure du projet

Voici la structure dÃ©taillÃ©e du projet, enrichie avec des explications pour mieux comprendre le rÃ´le de chaque fichier et dossier :

TEST-CLEAN 
â”‚  
â”œâ”€â”€ ğŸ“ .venv  
â”‚   â†’ Environnement virtuel Python qui contient tous les packages et dÃ©pendances nÃ©cessaires au projet.  
â”‚  
â”œâ”€â”€ ğŸ“ analyse  
â”‚   â†’ Scripts dâ€™analyse intelligente (NLP, classification, rÃ©sumÃ©). Câ€™est le cerveau du projet cÃ´tÃ© traitement du texte.  
â”‚   â”œâ”€â”€ ğŸ“ __pycache__  
â”‚   â”‚   â†’ Cache Python gÃ©nÃ©rÃ© automatiquement (peut Ãªtre ignorÃ©).  
â”‚   â”œâ”€â”€ ğŸ“„ analyseur_semantique.py  
â”‚   â”‚   â†’ Analyse le sens et les relations entre les mots pour enrichir la comprÃ©hension des textes.  
â”‚   â”œâ”€â”€ ğŸ“„ classifier_theme.py  
â”‚   â”‚   â†’ Classe les textes dans des thÃ©matiques prÃ©cises (ex : marketing, IT, design).  
â”‚   â””â”€â”€ ğŸ“„ resumeur.py  
â”‚       â†’ GÃ©nÃ¨re automatiquement des rÃ©sumÃ©s synthÃ©tiques et clairs Ã  partir des textes collectÃ©s.  
â”‚  
â”œâ”€â”€ ğŸ“ debug  
â”‚   â†’ Contient des fichiers et logs utiles pour tester et corriger les erreurs du projet.  
â”‚  
â”œâ”€â”€ ğŸ“ drivers  
â”‚   â†’ Drivers pour automatiser les navigateurs avec Selenium (Chrome, Edge).  
â”‚   â”œâ”€â”€ ğŸ“ chromedriver-win64  
â”‚   â”œâ”€â”€ ğŸ“ edgedriver_win64  
â”‚   â”œâ”€â”€ âš™ï¸ chromedriver.exe  
â”‚   â”œâ”€â”€ ğŸ“¦ edgedriver_win64.zip  
â”‚   â””â”€â”€ âš™ï¸ msedgedriver.exe  
â”‚       â†’ Sans ces drivers, impossible de contrÃ´ler les navigateurs pour extraire les donnÃ©es.  
â”‚  
â”œâ”€â”€ ğŸ“ fonts  
â”‚   â†’ Polices personnalisÃ©es utilisÃ©es dans les rapports PDF et les visualisations graphiques.  
â”‚  
â”œâ”€â”€ ğŸ“ logos  
â”‚   â†’ Regroupe les logos des entreprises et plateformes scrappÃ©es, utilisÃ©s dans les rapports.  
â”‚  
â”œâ”€â”€ ğŸ“ models  
â”‚   â†’ ModÃ¨les dâ€™IA locaux utilisÃ©s pour les analyses avancÃ©es.  
â”‚   â””â”€â”€ ğŸ§  mistral-7b-instruct-v0.1.Q4_K_M.gguf  
â”‚       â†’ Un modÃ¨le NLP performant pour rÃ©sumer, classer et analyser les textes.  
â”‚  
â”œâ”€â”€ ğŸ“ scraping  
â”‚   â†’ Le moteur de collecte des donnÃ©es. Tous les scripts pour extraire, nettoyer et prÃ©parer les informations.  
â”‚   â”œâ”€â”€ ğŸ“ __pycache__  
â”‚   â”œâ”€â”€ ğŸ“ cleaned  
â”‚   â”‚   â†’ DonnÃ©es dÃ©jÃ  nettoyÃ©es aprÃ¨s le scraping, prÃªtes Ã  Ãªtre analysÃ©es.  
â”‚   â”œâ”€â”€ ğŸ“„ ai_analysis.py  
â”‚   â”‚   â†’ Analyse assistÃ©e par IA du contenu collectÃ©.  
â”‚   â”œâ”€â”€ ğŸ“„ browser.py  
â”‚   â”‚   â†’ GÃ¨re le navigateur Selenium (ouvrir, naviguer, fermer).  
â”‚   â”œâ”€â”€ ğŸ“„ cleaner.py  
â”‚   â”‚   â†’ Nettoie les donnÃ©es brutes en supprimant le bruit (balises HTML, caractÃ¨res spÃ©ciaux, etc.).  
â”‚   â”œâ”€â”€ ğŸ“„ crawler.py  
â”‚   â”‚   â†’ Parcourt automatiquement les pages pour rÃ©cupÃ©rer des liens et contenus.  
â”‚   â”œâ”€â”€ ğŸ“„ extractor.py  
â”‚   â”‚   â†’ Extrait des informations ciblÃ©es comme emails, tÃ©lÃ©phones, descriptions.  
â”‚   â”œâ”€â”€ ğŸ“„ scraper_dynamic.py  
â”‚   â”‚   â†’ Scraping des sites dynamiques (JavaScript, contenus gÃ©nÃ©rÃ©s en temps rÃ©el).  
â”‚   â”œâ”€â”€ ğŸ“„ scraper_static.py  
â”‚   â”‚   â†’ Scraping plus simple, basÃ© uniquement sur le HTML statique.  
â”‚   â”œâ”€â”€ ğŸ“„ section_extractor.py  
â”‚   â”‚   â†’ RepÃ¨re et extrait des sections prÃ©cises (ex : "Ã€ propos", "Services").  
â”‚   â””â”€â”€ ğŸ“„ text_classifier.py  
â”‚       â†’ Classe automatiquement les textes scrappÃ©s par type ou catÃ©gorie.  
â”‚  
â”œâ”€â”€ ğŸ“ screenshots  
â”‚   â†’ Captures dâ€™Ã©cran des pages scrappÃ©es, utiles pour vÃ©rifier ou documenter les rÃ©sultats.  
â”‚  
â”œâ”€â”€ ğŸ“ utils  
â”‚   â†’ BoÃ®te Ã  outils du projet : tout ce qui facilite la manipulation des donnÃ©es et des rapports.  
â”‚   â”œâ”€â”€ ğŸ“ __pycache__  
â”‚   â”œâ”€â”€ ğŸ“„ analyse_nlp.py  
â”‚   â”‚   â†’ Fonctions de traitement NLP (analyse linguistique avancÃ©e).  
â”‚   â”œâ”€â”€ ğŸ“„ analyse_tfidf.py  
â”‚   â”‚   â†’ Calcule lâ€™importance des mots dans les textes grÃ¢ce Ã  la mÃ©thode TF-IDF.  
â”‚   â”œâ”€â”€ ğŸ“„ detection.py  
â”‚   â”‚   â†’ DÃ©tecte des infos clÃ©s comme emails, numÃ©ros de tÃ©lÃ©phone, adresses.  
â”‚   â”œâ”€â”€ ğŸ“„ io_handler.py  
â”‚   â”‚   â†’ GÃ¨re la lecture et lâ€™Ã©criture des fichiers (JSON, CSV, etc.).  
â”‚   â”œâ”€â”€ ğŸ“„ pdf_report.py  
â”‚   â”‚   â†’ GÃ©nÃ¨re automatiquement des rapports PDF professionnels.  
â”‚   â”œâ”€â”€ ğŸ“„ rapport_final.py  
â”‚   â”‚   â†’ Assemble toutes les analyses en un rapport final clair et structurÃ©.  
â”‚   â””â”€â”€ ğŸ“„ synthese_nlp.py  
â”‚       â†’ Produit une synthÃ¨se globale des rÃ©sultats NLP (rÃ©sumÃ©s, mots-clÃ©s, tendances).  
â”‚  
â”œâ”€â”€ ğŸ“ visualisations  
â”‚   â†’ RÃ©sultats visuels : graphiques et nuages de mots pour illustrer les analyses.  
â”‚   â”œâ”€â”€ ğŸ–¼ global_bigrams_wc.png  
â”‚   â”œâ”€â”€ ğŸ–¼ global_bigrams.png  
â”‚   â”œâ”€â”€ ğŸ–¼ global_trigrams_wc.png  
â”‚   â””â”€â”€ ğŸ–¼ global_trigrams.png  
â”‚       â†’ Ces images aident Ã  comprendre rapidement les thÃ¨mes dominants.  
â”‚  
â”œâ”€â”€ ğŸ“ content_cleaner.log  
â”‚   â†’ Journal listant les Ã©tapes de nettoyage du contenu.  
â”œâ”€â”€ ğŸ“„ dashboard.py  
â”‚   â†’ Interface utilisateur (Streamlit). La vitrine interactive du projet.  
â”œâ”€â”€ ğŸ“„ envoi_mail.py  
â”‚   â†’ Automatise lâ€™envoi des rapports PDF aux destinataires (Ã©quipe, clients).  
â”œâ”€â”€ ğŸ“„ json_to_pdf.py  
â”‚   â†’ Convertit des donnÃ©es JSON en rapports PDF lisibles.  
â”œâ”€â”€ ğŸ—‚ logo_mapping.json  
â”‚   â†’ Associe chaque entreprise Ã  son logo pour enrichir les rapports visuellement.  
â”œâ”€â”€ ğŸ“„ multi_scraper.py  
â”‚   â†’ Lance plusieurs scrapers en parallÃ¨le pour gagner du temps.  
â”œâ”€â”€ ğŸ“„ nettoyage_base.py  
â”‚   â†’ Nettoie la base de donnÃ©es consolidÃ©e.  
â”œâ”€â”€ ğŸ“„ nlp_tfidf_visualisation.py  
â”‚   â†’ GÃ©nÃ¨re des visualisations des scores TF-IDF (importance des mots).  
â”œâ”€â”€ ğŸ“ pipeline.log  
â”‚   â†’ Journal dâ€™exÃ©cution complet du pipeline.  
â”œâ”€â”€ ğŸ“„ runall.py  
â”‚   â†’ Script chef dâ€™orchestre qui lance tout le pipeline (scraping â†’ analyse â†’ rapport).  
â”œâ”€â”€ ğŸ“ scraper.log  
â”‚   â†’ Journal dÃ©diÃ© uniquement au scraping.  
â”œâ”€â”€ ğŸ“„ style.css  
â”‚   â†’ Feuille de style qui personnalise lâ€™apparence du Dashboard.  
â”œâ”€â”€ ğŸ“„ sites.csv  
â”‚   â†’ Liste des sites web Ã  analyser (point de dÃ©part du scraping).  
â”‚  
â”œâ”€â”€ ğŸ“„ resultats_clean.json  
â”‚   â†’ RÃ©sultats aprÃ¨s nettoyage.  
â”œâ”€â”€ ğŸ“„ resultats_final.json  
â”‚   â†’ RÃ©sultats finaux consolidÃ©s et prÃªts pour les rapports.  
â”œâ”€â”€ ğŸ“„ resultats.json  
â”‚   â†’ RÃ©sultats bruts directement issus du scraping.  
â”‚  
â”œâ”€â”€ ğŸ“„ rapport_entreprises.pdf  
â”‚   â†’ Rapport PDF focalisÃ© sur les entreprises.  
â”œâ”€â”€ ğŸ“„ rapport_final.pdf  
â”‚   â†’ Rapport PDF global (entreprises + freelances).  
â”œâ”€â”€ ğŸ–¼ rapport_freelance_*.png  
â”‚   â†’ Graphiques dÃ©diÃ©s aux freelances.  
â””â”€â”€ ğŸ“„ rapport_sites.pdf  
    â†’ Rapport PDF par site scrappÃ©.  

---

## âœ¨ FonctionnalitÃ©s principales

Le projet offre une gamme complÃ¨te de fonctionnalitÃ©s pour automatiser la veille concurrentielle et produire des rÃ©sultats exploitables :

### 1. **Scraping multi-site**
- **Description** : Collecte des donnÃ©es Ã  partir de plusieurs sites web en parallÃ¨le, en combinant des approches dynamiques (JavaScript) et statiques (HTML brut).
- **Impact** : RÃ©duit le temps de collecte des donnÃ©es et garantit une couverture maximale des sources.

### 2. **Nettoyage et structuration des donnÃ©es**
- **Description** : Supprime les Ã©lÃ©ments inutiles (URLs, images, etc.), dÃ©tecte la langue des contenus et structure les donnÃ©es en catÃ©gories exploitables (services, technologies, clients).
- **Impact** : PrÃ©pare les donnÃ©es pour une analyse approfondie et garantit leur qualitÃ©.

### 3. **Analyse NLP avancÃ©e**
- **Description** : Applique des techniques de lemmatisation, tokenisation et TF-IDF pour extraire les mots-clÃ©s les plus pertinents. GÃ©nÃ¨re Ã©galement des statistiques globales sur les cooccurrences et les tendances.
- **Impact** : Identifie les termes et expressions clÃ©s pour mieux comprendre les tendances du marchÃ©.

### 4. **Visualisations interactives et statiques**
- **Description** : GÃ©nÃ¨re des graphiques (histogrammes, nuages de mots, heatmaps) et des rÃ©seaux interactifs pour explorer les donnÃ©es.
- **Impact** : Facilite l'interprÃ©tation des rÃ©sultats et leur prÃ©sentation aux parties prenantes.

### 5. **GÃ©nÃ©ration de rapports PDF**
- **Description** : Produit des rapports PDF professionnels avec des sections dÃ©taillÃ©es pour chaque entreprise, incluant des introductions gÃ©nÃ©rÃ©es automatiquement.
- **Impact** : Fournit un livrable clÃ© pour les clients ou les dÃ©cideurs.

### 6. **Dashboard interactif**
- **Description** : Interface utilisateur intuitive pour explorer les rÃ©sultats, filtrer les donnÃ©es et tÃ©lÃ©charger les rapports.
- **Impact** : Rend les rÃ©sultats accessibles et exploitables par tous les membres de l'Ã©quipe.

### 7. **Automatisation de l'envoi des rapports**
- **Description** : Envoie automatiquement les rapports par email aux parties prenantes, avec des piÃ¨ces jointes et un contenu personnalisÃ©.
- **Impact** : RÃ©duit les tÃ¢ches manuelles et garantit une communication rÃ©guliÃ¨re.

---

## ğŸ› ï¸ Technologies utilisÃ©es

Le projet repose sur un ensemble de technologies modernes et performantes, soigneusement sÃ©lectionnÃ©es pour rÃ©pondre aux besoins spÃ©cifiques de chaque Ã©tape du pipeline :

### 1. **Python**
- **Pourquoi ?** : Langage polyvalent et riche en bibliothÃ¨ques pour le scraping, l'analyse NLP et la visualisation.
- **Impact** : Permet une intÃ©gration fluide de toutes les Ã©tapes du pipeline.

### 2. **Selenium & BeautifulSoup**
- **Pourquoi ?** : Selenium pour le scraping dynamique (JavaScript) et BeautifulSoup pour le scraping statique (HTML brut).
- **Impact** : Garantit une collecte de donnÃ©es robuste et flexible.

### 3. **Spacy**
- **Pourquoi ?** : Pour la tokenisation, la lemmatisation et la dÃ©tection de langue.
- **Impact** : Fournit une base solide pour les analyses NLP.

### 4. **Scikit-learn**
- **Pourquoi ?** : Pour le calcul des scores TF-IDF et l'extraction des mots-clÃ©s.
- **Impact** : Identifie les termes les plus pertinents dans les donnÃ©es textuelles.

### 5. **Matplotlib, Seaborn & Plotly**
- **Pourquoi ?** : Pour crÃ©er des visualisations statiques et interactives.
- **Impact** : Facilite l'exploration et la prÃ©sentation des rÃ©sultats.

### 6. **FPDF**
- **Pourquoi ?** : Pour gÃ©nÃ©rer des rapports PDF professionnels.
- **Impact** : Produit des livrables clairs et bien structurÃ©s.

### 7. **Streamlit**
- **Pourquoi ?** : Pour dÃ©velopper le Dashboard interactif.
- **Impact** : Offre une interface utilisateur intuitive et moderne.

### 8. **Llama.cpp**
- **Pourquoi ?** : Pour utiliser un modÃ¨le NLP local (Mistral) pour les analyses avancÃ©es.
- **Impact** : Permet des analyses sÃ©mantiques prÃ©cises sans dÃ©pendre d'une API externe.

---

## ğŸ“– Manuel d'utilisation

### PrÃ©requis :
1. **Python 3.8+** : Assurez-vous que Python est installÃ© sur votre machine.
2. **Navigateurs et drivers** :
   - Installez **Google Chrome** ou **Microsoft Edge**.
   - TÃ©lÃ©chargez les drivers correspondants (ex. `chromedriver.exe`).

### Installation des dÃ©pendances :
1. Clonez le projet :

   git clone https://github.com/IkramKhemiri/Veille-concurrentielle-automatis-e-avec-IA.git

2. CrÃ©ez un environnement virtuel :

python -m venv .venv
source .venv/bin/activate  # Sur Windows : .venv\Scripts\activate

3. Installez les dÃ©pendances :

pip install -r requirements.txt

4. TÃ©lÃ©chargez les modÃ¨les NLP nÃ©cessaires :

python -m spacy download fr_core_news_md
python -m spacy download en_core_web_md

5. ExÃ©cution du pipeline complet :
python runall.py

5. 1. Lancez le script principal :

python runall.py

5. 2. AccÃ©dez au Dashboard :

streamlit run dashboard.py

5. 3. Explorez les rÃ©sultats et tÃ©lÃ©chargez les rapports.


