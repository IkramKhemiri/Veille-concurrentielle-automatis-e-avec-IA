"""
R√¥le global :
Ce module est con√ßu pour effectuer une analyse linguistique avanc√©e (NLP) sur des textes extraits de sites web. 
Il d√©tecte la langue, extrait les mots-cl√©s, les lemmes et les tokens, et enrichit les donn√©es avec des informations 
linguistiques utiles. Il prend en charge plusieurs langues gr√¢ce √† des mod√®les Spacy.

Pourquoi il est important :
Dans le pipeline global (scraping ‚Üí analyse ‚Üí visualisation ‚Üí rapport), ce module joue un r√¥le cl√© en ajoutant une couche 
d'analyse linguistique aux donn√©es textuelles. Cela permet d'extraire des informations pertinentes et de mieux comprendre 
le contenu des sites web. Sans cette √©tape, les donn√©es textuelles resteraient brutes et moins exploitables.

Comment il aide dans le pipeline :
- **Scraping** : Les donn√©es textuelles extraites sont souvent volumineuses et non analys√©es. Ce module les structure et les enrichit.
- **Analyse** : Fournit des informations linguistiques comme les mots-cl√©s et les lemmes pour une analyse approfondie.
- **Visualisation** : Les mots-cl√©s extraits peuvent √™tre utilis√©s pour cr√©er des nuages de mots ou des graphiques.
- **Rapport** : Les donn√©es enrichies permettent de g√©n√©rer des rapports plus d√©taill√©s et informatifs.

Technologies utilis√©es :
- **Spacy** : Pour effectuer l'analyse linguistique (lemmatisation, extraction de tokens, etc.).
- **Langdetect** : Pour d√©tecter automatiquement la langue du texte.
- **Collections (Counter)** : Pour compter les occurrences des mots et extraire les mots-cl√©s les plus fr√©quents.
- **JSON** : Pour lire et √©crire les donn√©es enrichies dans des fichiers JSON.
"""

import spacy
import json
import langdetect
from collections import Counter
from typing import List, Dict

# Charger les mod√®les pour plusieurs langues
MODELS = {
    "fr": spacy.load("fr_core_news_md"),  # Mod√®le pour le fran√ßais
    "en": spacy.load("en_core_web_md"),  # Mod√®le pour l'anglais
    # "es": spacy.load("es_core_news_md"),  # D√©commentez pour ajouter le support de l'espagnol
}

def detect_lang(text: str) -> str:
    """
    R√¥le :
    D√©tecte automatiquement la langue d'un texte.

    Fonctionnalit√© :
    - Utilise la biblioth√®que `langdetect` pour identifier la langue dominante dans le texte.
    - Retourne "en" (anglais) par d√©faut en cas d'erreur.

    Importance :
    Cette fonction garantit que le texte est analys√© avec le mod√®le linguistique appropri√©, 
    ce qui am√©liore la pr√©cision de l'analyse NLP.

    Arguments :
    - `text` : Une cha√Æne de caract√®res repr√©sentant le texte √† analyser.

    Retour :
    Une cha√Æne de caract√®res repr√©sentant le code de la langue d√©tect√©e (par exemple, "fr", "en").
    """
    try:
        return langdetect.detect(text)
    except:
        return "en"  # Langue par d√©faut en cas d'erreur

def analyser_texte(text: str, lang: str = None) -> Dict:
    """
    R√¥le :
    Analyse un texte pour extraire des informations linguistiques comme les mots-cl√©s, les lemmes et les tokens.

    Fonctionnalit√© :
    - D√©tecte la langue du texte si elle n'est pas sp√©cifi√©e.
    - Utilise un mod√®le Spacy pour analyser le texte.
    - Extrait les tokens (mots), les lemmes (formes de base des mots) et les mots-cl√©s les plus fr√©quents.

    Importance :
    Cette fonction enrichit les donn√©es textuelles avec des informations linguistiques utiles, 
    facilitant leur exploitation dans les √©tapes suivantes.

    Arguments :
    - `text` : Une cha√Æne de caract√®res repr√©sentant le texte √† analyser.
    - `lang` : La langue du texte (facultatif). Si non sp√©cifi√©e, elle est d√©tect√©e automatiquement.

    Retour :
    Un dictionnaire contenant la langue d√©tect√©e, les mots-cl√©s, les lemmes et les tokens.
    """
    if not text or not isinstance(text, str):
        return {"mots_cles": []}

    lang = lang or detect_lang(text)
    nlp = MODELS.get(lang, MODELS["en"])  # Utilise le mod√®le correspondant √† la langue d√©tect√©e
    doc = nlp(text)

    tokens = [token.text.lower() for token in doc if token.is_alpha and not token.is_stop]
    lemmes = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]
    mots_cles = [word for word, freq in Counter(lemmes).most_common(10)]  # Top 10 des mots-cl√©s

    return {
        "langue": lang,
        "mots_cles": mots_cles,
        "lemmes": lemmes,
        "tokens": tokens
    }

def analyser_site(site: Dict) -> Dict:
    """
    R√¥le :
    Analyse linguistiquement le contenu textuel d'un site web.

    Fonctionnalit√© :
    - Combine les sections textuelles importantes du site (r√©sum√©, services, blog, etc.).
    - Effectue une analyse NLP sur le contenu combin√©.
    - Ajoute les r√©sultats de l'analyse au dictionnaire du site.

    Importance :
    Cette fonction enrichit les donn√©es d'un site avec des informations linguistiques, 
    rendant les donn√©es plus exploitables pour des analyses ou des visualisations.

    Arguments :
    - `site` : Un dictionnaire contenant les donn√©es d'un site web.

    Retour :
    Le dictionnaire du site enrichi avec les r√©sultats de l'analyse NLP.
    """
    contenu = " ".join(str(site.get(k, "")) for k in ["summary", "services", "blog", "clients", "jobs", "technologies"])
    contenu = contenu.strip().replace("\n", " ")
    result = analyser_texte(contenu)
    site["analyse_nlp"] = result
    return site

def enrichir_json_multilingue(fichier_in: str = "resultats_clean.json", fichier_out: str = "resultats_analyse.json"):
    """
    R√¥le :
    Enrichit un fichier JSON contenant des donn√©es de sites web avec des analyses linguistiques multilingues.

    Fonctionnalit√© :
    - Charge les donn√©es d'un fichier JSON.
    - Applique l'analyse NLP √† chaque site.
    - Sauvegarde les donn√©es enrichies dans un nouveau fichier JSON.

    Importance :
    Cette fonction automatise l'enrichissement des donn√©es textuelles avec des informations linguistiques, 
    facilitant leur exploitation dans des rapports ou des visualisations.

    Arguments :
    - `fichier_in` : Le chemin du fichier JSON d'entr√©e contenant les donn√©es brutes.
    - `fichier_out` : Le chemin du fichier JSON de sortie contenant les donn√©es enrichies.

    Retour :
    Aucun retour. Les r√©sultats sont sauvegard√©s dans le fichier de sortie.
    """
    with open(fichier_in, "r", encoding="utf-8") as f:
        data = json.load(f)

    enriched = [analyser_site(site) for site in data]

    with open(fichier_out, "w", encoding="utf-8") as f:
        json.dump(enriched, f, indent=2, ensure_ascii=False)

    print(f"‚úÖ NLP multilingue termin√© : {fichier_out}")

# ‚ûï Fonction main pour ex√©cution directe
if __name__ == "__main__":
    """
    R√¥le :
    Point d'entr√©e principal pour ex√©cuter l'analyse NLP multilingue sur un fichier JSON.

    Fonctionnalit√© :
    - Lance la fonction `enrichir_json_multilingue` pour traiter les donn√©es d'entr√©e.
    - Affiche un message de confirmation une fois le traitement termin√©.

    Importance :
    Permet d'ex√©cuter le script directement depuis la ligne de commande pour enrichir les donn√©es JSON avec des analyses NLP.
    """
    print("üîç Lancement du traitement NLP multilingue...")
    enrichir_json_multilingue()
